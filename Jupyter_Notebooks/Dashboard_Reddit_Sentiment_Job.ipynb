{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f11f7d-449c-4e00-bd08-8bc05575ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import praw\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import psycopg2\n",
    "#nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb3eeace-6ed0-4939-bd56-11edea1daa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = psycopg2.connect(\n",
    "            user='postgres', password='Data2023',\n",
    "            host='mads-capstone.cmohac77hep9.eu-north-1.rds.amazonaws.com', port=5432,\n",
    "            database=\"mads\"\n",
    "        )\n",
    "\n",
    "db_connection.autocommit = True\n",
    "\n",
    "cursor = db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e23798d4-c981-4d2f-87a2-8cf37a51c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRAW_for_dashboard():\n",
    "    def preprocess_df(df):\n",
    "        def preprocess_text(text):\n",
    "\n",
    "            # Remove specific unwanted characters\n",
    "            text = re.sub(r'[^A-Za-z0-9\\s,.!?;:()\\'\\\"-]', '', text)\n",
    "\n",
    "            # Strip whitespace\n",
    "            text = text.strip()\n",
    "\n",
    "            return text\n",
    "\n",
    "        try:\n",
    "            df['title'] = df['title'].fillna('')\n",
    "            df['title'] = df['title'].apply(preprocess_text)\n",
    "\n",
    "            # Create a new column with shifted values\n",
    "            df['title_prior'] = df['title'].shift(1)\n",
    "            # Drop rows where the value in 'ColumnToCheck' is the same as in 'ShiftedColumn'\n",
    "            df = df[df['title'] != df['title_prior']]\n",
    "            # drop the 'ShiftedColumn'\n",
    "            df = df.drop('title_prior', axis=1)\n",
    "\n",
    "        except:\n",
    "            print(f'No title found, skipping')\n",
    "\n",
    "\n",
    "        # handle blank \n",
    "        df['selftext'] = df['selftext'].fillna('') \n",
    "\n",
    "        # preprocess selftext\n",
    "        df['selftext'] = df['selftext'].apply(preprocess_text)\n",
    "\n",
    "        # localize the UTC time stamp\n",
    "        df['created_EST_date'] = pd.to_datetime(df['created_utc'], unit='s').dt.tz_localize('UTC').dt.tz_convert('America/New_York').dt.date\n",
    "\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def find_tickers(df):\n",
    " \n",
    "        # Load tickers from a CSV file\n",
    "        stocks = pd.read_csv(r'/root/Git Repo/SIADS_Capstone_Group17/Data/nasdaq_screener.csv')\n",
    "\n",
    "        # Directly convert the 'Symbol' column to a set\n",
    "        tickers_set = set(stocks['Symbol'])\n",
    "\n",
    "        # Use set union to add additional tickers\n",
    "        additional_tickers = {'BBBY'}\n",
    "        tickers_set = tickers_set.union(additional_tickers)\n",
    "\n",
    "        # Adjust the pattern to optionally include a leading '$'\n",
    "        # pattern = r'\\b\\$?(?:' + '|'.join(tickers_as_strings) + r')\\b'\n",
    "        # pattern = r'\\b\\$?(?:\\(?)(?:' + '|'.join(tickers_as_strings) + r')(?:\\)?)\\b'\n",
    "        pattern = r'\\b[A-Z]{2,5}\\b'\n",
    "        compiled_pattern = re.compile(pattern)\n",
    "\n",
    "\n",
    "\n",
    "        blacklist = {\n",
    "    #                 {'I', 'ELON', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR',\n",
    "    #              'DEC', 'BE',\n",
    "                    'IMO',# 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO',\n",
    "                    'DD',\n",
    "                    #'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD',\n",
    "    #              'TYS', \n",
    "                    'US',\n",
    "                    'USA',\n",
    "                    # 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', \n",
    "                    'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY',\n",
    "    #              'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR',\n",
    "                    'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO',\n",
    "    #              'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH',\n",
    "    #              'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA',\n",
    "    #              'USD', 'CPU', 'AT', 'GG', 'Mar', \n",
    "\n",
    "    #                # Jake added\n",
    "                    'RUN', # common\n",
    "                    'SAY', # common\n",
    "                    'EOD', # end of day\n",
    "                    'BIG', # common\n",
    "                    'LOW', # low / high\n",
    "                    'RSI', #relative strenght\n",
    "                    'DT', #double top\n",
    "                    'HUGE',\n",
    "                    'U', # you\n",
    "                    'AI', # Artificial Intelligence\n",
    "                    'DC', # washington DC\n",
    "                    'J', # as in J Powell\n",
    "                    'ES', # E-mini SP future\n",
    "                    'F', # f*ck\n",
    "                    'GO',\n",
    "                    'UK', # United Kingdom\n",
    "                    'EU', # european union\n",
    "                    'RH', # Robinhood, not Restoration Hardware\n",
    "                    'E', # E*trade brokerage\n",
    "                    'L', # L for loss, P&L etc\n",
    "                    'R', # common \n",
    "                    'K', # OK\n",
    "                    'B', # common in BBBY odd spacing (spam?)\n",
    "                    'TD', # TD Ameritrade brokerage\n",
    "                    'RYAN', # Ryan Cohen, CEO of GME\n",
    "                    'NYC', # New York City\n",
    "                    'REG', # reg SHO \n",
    "                    'SHO', # reg SHO \n",
    "                    'NEXT', # common\n",
    "                    'FREE', # spam\n",
    "                    'DM', # direct message\n",
    "                    'TV', # television\n",
    "                    'ENS', # ethereum name service, spam\n",
    "                    'IRS', # internal revenue service\n",
    "                    'PR', # public relations\n",
    "                    'IQ', # intelligence quotient\n",
    "                    'VS', # versus\n",
    "                    'PT', # price target\n",
    "                    'IBKR', # interactive brokers\n",
    "                    'GOOD', # common\n",
    "                    'OPEN', # market open\n",
    "                    'FCF', # free cash flow\n",
    "\n",
    "\n",
    "                    }\n",
    "\n",
    "        combined_blacklist = set(blacklist) | set(word.upper() for word in stopwords.words('english'))\n",
    "\n",
    "\n",
    "        def find_tickers(text, compiled_pattern, tickers_set, blacklist_set):\n",
    "            # Find all matches\n",
    "            potential_tickers = compiled_pattern.findall(text)\n",
    "            # Filter matches against the tickers list and ensure they are not in the blacklist\n",
    "            return list(set([ticker for ticker in potential_tickers if ticker in tickers_set and ticker not in combined_blacklist]))\n",
    "\n",
    "        try:\n",
    "            df['title_tickers'] = df['title'].apply(lambda x: find_tickers(x, compiled_pattern, tickers_set, combined_blacklist))\n",
    "        except KeyError:\n",
    "            print('title not found, working with comments?')\n",
    "\n",
    "\n",
    "        df['selftext_tickers'] = df['selftext'].apply(lambda x: find_tickers(x, compiled_pattern, tickers_set, combined_blacklist))\n",
    "\n",
    "        df['tickers'] = [list(set(x + y)) for x, y in zip(df['title_tickers'], df['selftext_tickers'])]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def add_vader_sentiment(df):\n",
    "\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "        added_words = {\n",
    "                'citron': -4.0,  \n",
    "                'hidenburg': -4.0,        \n",
    "                'moon': 4.0,\n",
    "                'highs': 2.0,\n",
    "                'mooning': 4.0,\n",
    "                'long': 2.0,\n",
    "                'short': -2.0,\n",
    "                'call': 4.0,\n",
    "                'calls': 4.0,    \n",
    "                'put': -4.0,\n",
    "                'puts': -4.0,    \n",
    "                'break': 2.0,\n",
    "                'tendie': 2.0,\n",
    "                'tendies': 2.0,\n",
    "                'town': 2.0,     \n",
    "                'overvalued': -3.0,\n",
    "                'undervalued': 3.0,\n",
    "                'buy': 4.0,\n",
    "                'sell': -4.0,\n",
    "                'gone': -1.0,\n",
    "                'gtfo': -1.7,\n",
    "                'paper': -1.7,\n",
    "                'bullish': 3.7,\n",
    "                'bearish': -3.7,\n",
    "                'bagholder': -1.7,\n",
    "                'stonk': 1.9,\n",
    "                'green': 1.9,\n",
    "                'money': 1.2,\n",
    "                'print': 2.2,\n",
    "                'rocket': 2.2,\n",
    "                'bull': 2.9,\n",
    "                'bear': -2.9,\n",
    "                'pumping': -1.0,\n",
    "                'sus': -3.0,\n",
    "                'offering': -2.3,\n",
    "                'rip': -4.0,\n",
    "                'downgrade': -3.0,\n",
    "                'upgrade': 3.0,     \n",
    "                'maintain': 1.0,          \n",
    "                'pump': 1.9,\n",
    "                'hot': 1.5,\n",
    "                'drop': -2.5,\n",
    "                'rebound': 1.5,  \n",
    "                'crack': 2.5,\n",
    "                '🚀': 3, # Jake ADDED THESE\n",
    "                '🌕': 3, # Jake ADDED THESE\n",
    "                'YOLO': 4, # Jake ADDED THESE\n",
    "                'ripping': 3,# Jake ADDED THESE\n",
    "                'regarded': 0, # Jake ADDED THESE\n",
    "                'squeeze':3, # Jake ADDED THESE\n",
    "                }\n",
    "\n",
    "        vader.lexicon.update(added_words)\n",
    "\n",
    "        def safe_sentiment(text):\n",
    "            try:\n",
    "                # Ensure the input is a non-empty string\n",
    "                if not isinstance(text, str) or not text.strip():\n",
    "                    return 0\n",
    "\n",
    "                # Analyze the sentiment\n",
    "                sentiment_dict = vader.polarity_scores(text)\n",
    "                return sentiment_dict.get('compound', 0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text: '{text}' (type: {type(text)}). Error: {e}\")\n",
    "                return 0\n",
    "\n",
    "        # Apply the function\n",
    "        try:\n",
    "            df['title_sentiment'] = df['title'].apply(safe_sentiment)\n",
    "        except:\n",
    "            print('Titles not found, is this a comments file?')\n",
    "            df['title_sentiment'] = 0\n",
    "\n",
    "        df['selftext_sentiment'] = df['selftext'].apply(safe_sentiment)\n",
    "\n",
    "\n",
    "        def non_zero_average(row):\n",
    "            sentiments = [row['title_sentiment'], row['selftext_sentiment']]\n",
    "            non_zero_sentiments = [s for s in sentiments if s != 0]\n",
    "\n",
    "            if not non_zero_sentiments:\n",
    "                return 0  # Return 0 if both sentiments are zero\n",
    "\n",
    "            return sum(non_zero_sentiments) / len(non_zero_sentiments)\n",
    "\n",
    "        # Apply the function to calculate overall sentiment\n",
    "        df['overall_sentiment'] = df.apply(non_zero_average, axis=1)\n",
    "\n",
    "        df['score_weighted_sentiment'] = df['overall_sentiment'] * df['score']\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_reddit_praw_submissions(limit):\n",
    "    \n",
    "        client_id = 'aWEYVIaAoJGlCPja3awh0A'\n",
    "        secret = 'gOR5FfkvsTH3MJ0IHRSImToTwt0PSQ'\n",
    "\n",
    "        reddit = praw.Reddit(\n",
    "                            client_id=client_id,\n",
    "                            client_secret=secret,\n",
    "                            user_agent=\"MADS/0.1 by TeamSafari\",\n",
    "                        )\n",
    "        submissions_data = []\n",
    "\n",
    "        for submission in reddit.subreddit(\"wallstreetbets\").new(limit=limit):\n",
    "            # print(dir(submission))\n",
    "            data = {\n",
    "                'id': submission.id,\n",
    "                'subreddit_id': submission.subreddit_id,\n",
    "                'subreddit': submission.subreddit,\n",
    "                'author': submission.author,\n",
    "                'created_utc': submission.created_utc,\n",
    "                'permalink': submission.permalink,\n",
    "                'title': submission.title,\n",
    "                'selftext': submission.selftext,\n",
    "                'num_comments': submission.num_comments,\n",
    "                'score': submission.score,\n",
    "                'flair': submission.link_flair_text,\n",
    "                'removal_reason':submission.removal_reason,\n",
    "\n",
    "\n",
    "                # Add more fields as needed\n",
    "            }\n",
    "            submissions_data.append(data)\n",
    "\n",
    "        df = pd.DataFrame(submissions_data)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    df = get_reddit_praw_submissions(limit=1000)\n",
    "    praw_df = preprocess_df(df)\n",
    "    praw_df = find_tickers(praw_df)\n",
    "    praw_df = add_vader_sentiment(praw_df)\n",
    "    \n",
    "    \n",
    "    # display(praw_df)\n",
    "    \n",
    "    \n",
    "    # create cumulative_sentiment_sorted_df\n",
    "    exploded_df = praw_df.explode('tickers')\n",
    "    cumulative_sentiment = exploded_df.groupby('tickers')['overall_sentiment'].sum().reset_index() # Group by 'tickers'\n",
    "    cumulative_sentiment.columns = ['Ticker', 'Cumulative Overall Sentiment'] # Rename columns for clarity\n",
    "    cumulative_sentiment_sorted = cumulative_sentiment.sort_values(by='Cumulative Overall Sentiment', ascending=False)\n",
    "    # display(cumulative_sentiment_sorted)\n",
    "\n",
    "    # Group by 'tickers' and sum the 'score_weighted_sentiment'\n",
    "    cumulative_weighted_sentiment = exploded_df.groupby('tickers')['score_weighted_sentiment'].sum().reset_index()\n",
    "    cumulative_weighted_sentiment.columns = ['Ticker', 'Cumulative Weighted Sentiment'] # Rename columns for clarity\n",
    "    cumulative_weighted_sentiment_sorted = cumulative_weighted_sentiment.sort_values(by='Cumulative Weighted Sentiment', ascending=False)\n",
    "    cumulative_weighted_sentiment_sorted['Date'] = praw_df['created_EST_date']\n",
    "    cumulative_weighted_sentiment_sorted['Date'].fillna(praw_df['created_EST_date'].unique()[0],inplace=True)\n",
    "    # display(cumulative_weighted_sentiment_sorted)\n",
    "\n",
    "    daily_sentiment_df = cumulative_sentiment_sorted.merge(cumulative_weighted_sentiment_sorted, on='Ticker')\n",
    "    \n",
    "    # Explode the DataFrame if 'tickers' column contains lists\n",
    "    # exploded_df = praw_df.explode('tickers')\n",
    "\n",
    "    expected_columns = ['tickers', 'title', 'permalink', 'overall_sentiment']\n",
    "\n",
    "    # Check if all expected columns are in the DataFrame\n",
    "    if not all(column in exploded_df.columns for column in expected_columns):\n",
    "        raise ValueError(\"DataFrame does not contain the expected columns.\")\n",
    "\n",
    "    # Base URL to prepend to permalinks\n",
    "    base_url = 'https://www.reddit.com/'\n",
    "    \n",
    "    # Aggregate submission details with the base URL prepended to permalinks\n",
    "    #submission_details = exploded_df.groupby('tickers').apply(\n",
    "    #    lambda x: [(title, base_url + permalink, sentiment) \n",
    "    #               for title, permalink, sentiment in zip(x['title'], x['permalink'], x['overall_sentiment'])]\n",
    "    #).reset_index(name='Submissions')\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    #submission_details.columns = ['Ticker', 'Submissions']\n",
    "    exploded_df = exploded_df.rename(columns={\"tickers\": \"Ticker\"})\n",
    "    exploded_df = exploded_df[[\"Ticker\", \"title\", \"permalink\", \"overall_sentiment\"]]\n",
    "\n",
    "    # Merge with daily_sentiment_df\n",
    "    daily_sentiment_df = daily_sentiment_df.merge(exploded_df, on='Ticker', how='left')\n",
    "    daily_sentiment_df[\"title\"] = daily_sentiment_df[\"title\"].str.replace(\",\", \";\")\n",
    "    \n",
    "    return daily_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25bd281e-e926-4901-bd2c-3b63b5599332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 17.9 ms, total: 1.9 s\n",
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Cumulative Overall Sentiment</th>\n",
       "      <th>Cumulative Weighted Sentiment</th>\n",
       "      <th>Date</th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>8.89415</td>\n",
       "      <td>310.8972</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>Odds of the SAVE case being decided on or befo...</td>\n",
       "      <td>/r/wallstreetbets/comments/18epb7p/odds_of_the...</td>\n",
       "      <td>0.78770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>8.89415</td>\n",
       "      <td>310.8972</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>SAVE merger question</td>\n",
       "      <td>/r/wallstreetbets/comments/18cl5jf/save_merger...</td>\n",
       "      <td>0.77200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>8.89415</td>\n",
       "      <td>310.8972</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>SAVE trial bullish quotes from the judge</td>\n",
       "      <td>/r/wallstreetbets/comments/18by8rd/save_trial_...</td>\n",
       "      <td>0.89165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>8.89415</td>\n",
       "      <td>310.8972</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>What happens to SAVE if JetBlue merger is bloc...</td>\n",
       "      <td>/r/wallstreetbets/comments/18bjkra/what_happen...</td>\n",
       "      <td>0.64795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>8.89415</td>\n",
       "      <td>310.8972</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>What are your thoughts on the SpiritJetblue me...</td>\n",
       "      <td>/r/wallstreetbets/comments/18aq3j1/what_are_yo...</td>\n",
       "      <td>0.76030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>BBVA</td>\n",
       "      <td>-0.95110</td>\n",
       "      <td>-6.6577</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>Shorting select Argentinian companies</td>\n",
       "      <td>/r/wallstreetbets/comments/185f4oj/shorting_se...</td>\n",
       "      <td>-0.95110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>NOV</td>\n",
       "      <td>-0.95110</td>\n",
       "      <td>-6.6577</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>Shorting select Argentinian companies</td>\n",
       "      <td>/r/wallstreetbets/comments/185f4oj/shorting_se...</td>\n",
       "      <td>-0.95110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>YPF</td>\n",
       "      <td>-0.95110</td>\n",
       "      <td>-6.6577</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>Shorting select Argentinian companies</td>\n",
       "      <td>/r/wallstreetbets/comments/185f4oj/shorting_se...</td>\n",
       "      <td>-0.95110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>DHI</td>\n",
       "      <td>-1.30180</td>\n",
       "      <td>-45.7194</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>Did Warren Buffett make a mistake? BUY DHI PUTS.</td>\n",
       "      <td>/r/wallstreetbets/comments/18cz9ap/did_warren_...</td>\n",
       "      <td>-0.59340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>DHI</td>\n",
       "      <td>-1.30180</td>\n",
       "      <td>-45.7194</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>Bhutan Built A Bitcoin Mine On The Site Of Its...</td>\n",
       "      <td>/r/wallstreetbets/comments/18c7oij/bhutan_buil...</td>\n",
       "      <td>-0.70840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Cumulative Overall Sentiment  Cumulative Weighted Sentiment  \\\n",
       "0     SAVE                       8.89415                       310.8972   \n",
       "1     SAVE                       8.89415                       310.8972   \n",
       "2     SAVE                       8.89415                       310.8972   \n",
       "3     SAVE                       8.89415                       310.8972   \n",
       "4     SAVE                       8.89415                       310.8972   \n",
       "..     ...                           ...                            ...   \n",
       "414   BBVA                      -0.95110                        -6.6577   \n",
       "415    NOV                      -0.95110                        -6.6577   \n",
       "416    YPF                      -0.95110                        -6.6577   \n",
       "417    DHI                      -1.30180                       -45.7194   \n",
       "418    DHI                      -1.30180                       -45.7194   \n",
       "\n",
       "           Date                                              title  \\\n",
       "0    2023-12-07  Odds of the SAVE case being decided on or befo...   \n",
       "1    2023-12-07                               SAVE merger question   \n",
       "2    2023-12-07           SAVE trial bullish quotes from the judge   \n",
       "3    2023-12-07  What happens to SAVE if JetBlue merger is bloc...   \n",
       "4    2023-12-07  What are your thoughts on the SpiritJetblue me...   \n",
       "..          ...                                                ...   \n",
       "414  2023-12-09              Shorting select Argentinian companies   \n",
       "415  2023-12-07              Shorting select Argentinian companies   \n",
       "416  2023-12-06              Shorting select Argentinian companies   \n",
       "417  2023-12-08   Did Warren Buffett make a mistake? BUY DHI PUTS.   \n",
       "418  2023-12-08  Bhutan Built A Bitcoin Mine On The Site Of Its...   \n",
       "\n",
       "                                             permalink  overall_sentiment  \n",
       "0    /r/wallstreetbets/comments/18epb7p/odds_of_the...            0.78770  \n",
       "1    /r/wallstreetbets/comments/18cl5jf/save_merger...            0.77200  \n",
       "2    /r/wallstreetbets/comments/18by8rd/save_trial_...            0.89165  \n",
       "3    /r/wallstreetbets/comments/18bjkra/what_happen...            0.64795  \n",
       "4    /r/wallstreetbets/comments/18aq3j1/what_are_yo...            0.76030  \n",
       "..                                                 ...                ...  \n",
       "414  /r/wallstreetbets/comments/185f4oj/shorting_se...           -0.95110  \n",
       "415  /r/wallstreetbets/comments/185f4oj/shorting_se...           -0.95110  \n",
       "416  /r/wallstreetbets/comments/185f4oj/shorting_se...           -0.95110  \n",
       "417  /r/wallstreetbets/comments/18cz9ap/did_warren_...           -0.59340  \n",
       "418  /r/wallstreetbets/comments/18c7oij/bhutan_buil...           -0.70840  \n",
       "\n",
       "[419 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "final_df = PRAW_for_dashboard()\n",
    "\n",
    "#final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67ad56-0e1d-434e-909c-7631cabed43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "query = '''ALTER TABLE reddit_sentiment_by_date\n",
    "                ADD COLUMN title text,\n",
    "                ADD COLUMN permalink text,\n",
    "                ADD COLUMN overall_sentiment float;\n",
    "'''\n",
    "\n",
    "\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2d89aba-9b42-4977-958f-bd90dde7c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"latest_sentiment.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8032d0e0-ba38-4a4a-bec6-e7718a6df4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tail latest_sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9be80c06-aac0-4252-b079-b6ea52a9872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"latest_sentiment.csv\", \"rb\") as fp:\n",
    "    cursor.copy_from(fp, \"reddit_sentiment_by_date\", sep=\",\", null=\"\", columns=[\"ticker\", \"cumm_overall_sentiment\", \"cumm_weighted_sentiment\", \"record_date\",  \"title\", \"permalink\", \"overall_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e432df13-59e0-40db-be7c-5d1f363884de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>cumm_overall_sentiment</th>\n",
       "      <th>cumm_weighted_sentiment</th>\n",
       "      <th>record_date</th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162372</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>-0.27480</td>\n",
       "      <td>-5.4960</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>bought AAOI 3 month ago at 14.80; went down as...</td>\n",
       "      <td>/r/wallstreetbets/comments/188r675/bought_aaoi...</td>\n",
       "      <td>-0.27480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162333</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.08140</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Long Airline stocks Jets AAL UAL as of today</td>\n",
       "      <td>/r/wallstreetbets/comments/186rw7p/long_airlin...</td>\n",
       "      <td>0.08140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162140</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.70275</td>\n",
       "      <td>30.5043</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Apple's head of iphone and Apple watch design ...</td>\n",
       "      <td>/r/wallstreetbets/comments/18ecxrr/apples_head...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162141</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.70275</td>\n",
       "      <td>30.5043</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Dont be a Chad! Sometimes we have to seek Valu...</td>\n",
       "      <td>/r/wallstreetbets/comments/18akdap/dont_be_a_c...</td>\n",
       "      <td>0.87495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162142</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.70275</td>\n",
       "      <td>30.5043</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Paramount and Apple teaming Up?</td>\n",
       "      <td>/r/wallstreetbets/comments/188bdh8/paramount_a...</td>\n",
       "      <td>0.37550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ticker  cumm_overall_sentiment  cumm_weighted_sentiment record_date  \\\n",
       "0  162372   AAOI                -0.27480                  -5.4960  2023-12-10   \n",
       "1  162333    AAL                 0.08140                   0.2442  2023-12-10   \n",
       "2  162140   AAPL                 1.70275                  30.5043  2023-12-10   \n",
       "3  162141   AAPL                 1.70275                  30.5043  2023-12-10   \n",
       "4  162142   AAPL                 1.70275                  30.5043  2023-12-10   \n",
       "\n",
       "                                               title  \\\n",
       "0  bought AAOI 3 month ago at 14.80; went down as...   \n",
       "1       Long Airline stocks Jets AAL UAL as of today   \n",
       "2  Apple's head of iphone and Apple watch design ...   \n",
       "3  Dont be a Chad! Sometimes we have to seek Valu...   \n",
       "4                    Paramount and Apple teaming Up?   \n",
       "\n",
       "                                           permalink  overall_sentiment  \n",
       "0  /r/wallstreetbets/comments/188r675/bought_aaoi...           -0.27480  \n",
       "1  /r/wallstreetbets/comments/186rw7p/long_airlin...            0.08140  \n",
       "2  /r/wallstreetbets/comments/18ecxrr/apples_head...            0.00000  \n",
       "3  /r/wallstreetbets/comments/18akdap/dont_be_a_c...            0.87495  \n",
       "4  /r/wallstreetbets/comments/188bdh8/paramount_a...            0.37550  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_query = \"SELECT * FROM reddit_sentiment_by_date ORDER BY record_date DESC LIMIT 100;\"\n",
    "\n",
    "cursor.execute(select_query)\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "records = []\n",
    "for row in rows:\n",
    "    records.append([row[0], row[1],row[2], row[3], row[4], row[5], row[6], row[7]])\n",
    "    \n",
    "df = pd.DataFrame(records, columns=[\"id\", \"ticker\", \"cumm_overall_sentiment\", \"cumm_weighted_sentiment\", \"record_date\", \"title\", \"permalink\", \"overall_sentiment\"])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "670bd33c-341f-4161-989f-cfd389558d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection.close()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
