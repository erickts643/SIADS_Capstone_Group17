{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64295414-bb64-43c1-8b5a-d2f396379c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yahoo_fin import stock_info as finance\n",
    "\n",
    "# Mock function to mimic the behavior of finance.get_data\n",
    "def get_data(ticker, sdate, edate):\n",
    "    # Assume this function returns a DataFrame similar to the one produced by finance.get_data\n",
    "    # For demonstration, we're generating a DataFrame with a date range and mock data\n",
    "    return finance.get_data(ticker, sdate, edate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22121f61-3370-418d-8e44-81c16ecc0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9821/323460992.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  current_z_score = (df.iloc[i]['PriceChange'] - rolling_mean[i]) / rolling_std[i]\n",
      "/tmp/ipykernel_9821/323460992.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  future_z_score = (future_price_change - rolling_mean[i+lag_day]) / rolling_std[i+lag_day]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TriggerDate</th>\n",
       "      <th>TriggerClose</th>\n",
       "      <th>PriceJumpDate</th>\n",
       "      <th>Close</th>\n",
       "      <th>PriceJumpZScore</th>\n",
       "      <th>DaysAfterTrigger</th>\n",
       "      <th>SignificantPriceJump</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>1.1725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1.0350</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1.147500</td>\n",
       "      <td>3.288345</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>22.927500</td>\n",
       "      <td>3.827772</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>9.7800</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>16.252501</td>\n",
       "      <td>4.066758</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>25.3500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TriggerDate  TriggerClose PriceJumpDate      Close  PriceJumpZScore  \\\n",
       "22  2020-06-15        1.1725             0   0.000000         0.000000   \n",
       "1   2020-03-11        1.0350    2020-03-13   1.147500         3.288345   \n",
       "13  2021-02-22       11.5000    2021-02-24  22.927500         3.827772   \n",
       "11  2021-01-20        9.7800    2021-01-22  16.252501         4.066758   \n",
       "41  2022-10-07       25.3500             0   0.000000         0.000000   \n",
       "\n",
       "    DaysAfterTrigger  SignificantPriceJump Ticker  \n",
       "22               0.0                 False    GME  \n",
       "1                2.0                  True    GME  \n",
       "13               2.0                  True    GME  \n",
       "11               2.0                  True    GME  \n",
       "41               0.0                 False    GME  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_price_jumps(df, z_score_threshold=2, stability_threshold=1, lookback_period=90, lag_days_start=2, lag_days_end=5, \n",
    "                         include_negative_class=False, remove_duplicate_price_jump_dates=False):\n",
    "    # Calculating daily price changes\n",
    "    df['PriceChange'] = df['close'].pct_change()\n",
    "    \n",
    "    # Calculating rolling statistics\n",
    "    rolling_mean = df['PriceChange'].rolling(window=lookback_period).mean()\n",
    "    rolling_std = df['PriceChange'].rolling(window=lookback_period).std()\n",
    "    \n",
    "    # Identifying potential price jumps\n",
    "    positive_results = []\n",
    "    for i in range(lookback_period, len(df) - lag_days_end):\n",
    "        current_z_score = (df.iloc[i]['PriceChange'] - rolling_mean[i]) / rolling_std[i]\n",
    "        if abs(current_z_score) < stability_threshold:\n",
    "            for lag_day in range(lag_days_start, lag_days_end+1):\n",
    "                if i+lag_day < len(df):\n",
    "                    future_price_change = df.iloc[i+lag_day]['PriceChange']\n",
    "                    future_z_score = (future_price_change - rolling_mean[i+lag_day]) / rolling_std[i+lag_day]\n",
    "                    if future_z_score > z_score_threshold:\n",
    "                        positive_results.append({\n",
    "                            'TriggerDate': df.index[i].date(),\n",
    "                            'TriggerClose': df.iloc[i]['close'],\n",
    "                            'PriceJumpDate': df.index[i+lag_day].date(),\n",
    "                            'Close': df.iloc[i+lag_day]['close'],\n",
    "                            'PriceJumpZScore': future_z_score,\n",
    "                            'DaysAfterTrigger': lag_day,\n",
    "                            'SignificantPriceJump': True,\n",
    "                            'Ticker': df.iloc[0]['ticker']\n",
    "                        })\n",
    "                        break\n",
    "                        \n",
    "    # Convert positive results to DataFrame\n",
    "    positive_results_df = pd.DataFrame(positive_results)\n",
    "\n",
    "    # If remove_duplicate_price_jump_dates flag is set, remove duplicates\n",
    "    if remove_duplicate_price_jump_dates:\n",
    "        # Group by PriceJumpDate and randomly keep one record per group\n",
    "        positive_results_df = positive_results_df.groupby('PriceJumpDate').apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Sample negative class instances if required\n",
    "    negative_results = []\n",
    "    if include_negative_class:\n",
    "        num_positive = len(positive_results_df)\n",
    "        sampled_rows = df.iloc[lookback_period:len(df) - lag_days_end].sample(n=num_positive)\n",
    "        for _, row in sampled_rows.iterrows():\n",
    "            negative_results.append({\n",
    "                'TriggerDate': row.name.date(),\n",
    "                'TriggerClose': row['close'],\n",
    "                'PriceJumpDate': None,  # No price jump date for negative class\n",
    "                'Close': None,\n",
    "                'PriceJumpZScore': None,\n",
    "                'DaysAfterTrigger': None,\n",
    "                'SignificantPriceJump': False,\n",
    "                'Ticker': df.iloc[0]['ticker']\n",
    "            })\n",
    "\n",
    "    # Combine positive and negative results\n",
    "    combined_results = pd.DataFrame(positive_results_df.to_dict('records') + negative_results).fillna(0)\n",
    "\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "# Example usage\n",
    "df = get_data('GME', '2019-01-01', '2023-11-15')\n",
    "price_jumps_df = identify_price_jumps(df, z_score_threshold=2.5, stability_threshold=1, include_negative_class=True, remove_duplicate_price_jump_dates = True)\n",
    "price_jumps_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5284e5-56bc-4235-a719-aeee565a0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short sale volume\n",
    "\n",
    "class ShortSaleVolume:\n",
    "    \n",
    "    bucket = 'mads-capstone-2023' \n",
    "    data_key = 'FINRA_Short_Sale_Data2.csv' \n",
    "    data_location = 's3://{}/{}'.format(bucket, data_key) \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.has_downloaded = False \n",
    "    \n",
    "    # Function to download data from S3\n",
    "    def get_data(self):\n",
    "        if not self.has_downloaded:\n",
    "            self.df = pd.read_csv(self.data_location)\n",
    "            self.df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "            self.df['shortvolume'] = self.df['totalvolume'] - self.df['shortvolume']\n",
    "            self.df['longvolume'] = self.df['totalvolume'] - self.df['shortvolume']\n",
    "            self.df['short_ratio'] = 1 - self.df['short_ratio']\n",
    "            self.has_downloaded = True\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def short_ratio(self, ticker):\n",
    "        # Check if data has been downloaded locally\n",
    "        self.get_data()\n",
    "        \n",
    "        # Return data for ticker \n",
    "        df_ = self.df[self.df['ticker'] == ticker].copy()\n",
    "        df_['date'] = pd.to_datetime(df_['date'])\n",
    "        df_.set_index('date', inplace=True)\n",
    "        return df_\n",
    "\n",
    "    \n",
    "    def calculate_short_ratio_means(self, ticker='GME', include_diff=False, include_roc=False):\n",
    "        df = self.short_ratio(ticker)\n",
    "        periods = [1, 5, 10, 21, 42]\n",
    "        for period in periods:\n",
    "            df[f'short_ratio_mean_{period}'] = df['short_ratio'].rolling(window=period).mean()\n",
    "\n",
    "        if include_diff:\n",
    "            for i in range(len(periods)):\n",
    "                for j in range(i + 1, len(periods)):\n",
    "                    df[f'short_ratio_mean_{periods[i]}_div_mean_{periods[j]}'] = df[f'short_ratio_mean_{periods[i]}'] / df[f'short_ratio_mean_{periods[j]}']\n",
    "                    df[f'short_ratio_mean_{periods[j]}_div_mean_{periods[i]}'] = df[f'short_ratio_mean_{periods[j]}'] / df[f'short_ratio_mean_{periods[i]}']\n",
    "\n",
    "        if include_roc:\n",
    "            # print('working')\n",
    "            for col in df.columns:\n",
    "                if 'short_ratio_mean_' in col:\n",
    "                    df[f'{col}_roc'] = df[col].pct_change() * 100\n",
    "\n",
    "        result_df = df[[col for col in df.columns if 'short_ratio_mean_' in col or ('roc' in col and 'short_ratio_mean_' in col)]]\n",
    "        return result_df\n",
    "\n",
    "    def calculate_short_exempt_means(self, ticker='GME', include_diff=False, include_roc=False):\n",
    "        df = self.short_ratio(ticker)\n",
    "        periods = [1, 5, 10, 21, 42]\n",
    "\n",
    "        df['short_exempt_percent'] = (df['shortexemptvolume'] / df['totalvolume'])\n",
    "\n",
    "        for period in periods:\n",
    "            df[f'short_exempt_percent_mean_{period}'] = df['short_exempt_percent'].rolling(window=period).mean()\n",
    "\n",
    "        if include_diff:\n",
    "            for i in range(len(periods)):\n",
    "                for j in range(i + 1, len(periods)):\n",
    "                    df[f'short_exempt_percent_mean_{periods[i]}_div_mean_{periods[j]}'] = df[f'short_exempt_percent_mean_{periods[i]}'] / df[f'short_exempt_percent_mean_{periods[j]}']\n",
    "                    df[f'short_exempt_percent_mean_{periods[j]}_div_mean_{periods[i]}'] = df[f'short_exempt_percent_mean_{periods[j]}'] / df[f'short_exempt_percent_mean_{periods[i]}']\n",
    "\n",
    "        if include_roc:\n",
    "            for col in df.columns:\n",
    "                if 'short_exempt_percent_mean_' in col:\n",
    "                    df[f'{col}_roc'] = df[col].pct_change() * 100\n",
    "\n",
    "        result_df = df[[col for col in df.columns if 'short_exempt_percent_mean_' in col or ('roc' in col and 'short_exempt_percent_mean_' in col)]]\n",
    "        return result_df\n",
    "    \n",
    "    def calculate_investment_values(self, ticker='GME', days=20, investment_amount=1_000_000, include_diff=False, include_roc=False):\n",
    "        df = self.short_ratio(ticker)\n",
    "\n",
    "        # Retrieve closing prices from finance API\n",
    "        closing_prices = finance.get_data(ticker, df.index.min(), df.index.max())['close']\n",
    "        \n",
    "        # Merge closing prices with short ratio data\n",
    "        df = df.merge(closing_prices, left_index=True, right_index=True, how='left')\n",
    "\n",
    "        # Ensure short_exempt_percent column is calculated before its usage\n",
    "        df['short_exempt_percent'] = df['shortexemptvolume'] / df['totalvolume']\n",
    "\n",
    "        # Calculate net short volume and net short shares\n",
    "        df['net_short_volume'] = df['shortvolume'] - df['longvolume']\n",
    "        df['net_short_shares'] = investment_amount / df['close']\n",
    "\n",
    "        # Calculate cumulative net short volume and short exempt volume\n",
    "        df['cumulative_net_short'] = (df['net_short_volume'] * df['net_short_shares']).rolling(window=days).sum()\n",
    "        df['cumulative_short_exempt'] = (df['short_exempt_percent'] * df['net_short_shares']).rolling(window=days).sum()\n",
    "\n",
    "        # Calculate the cumulative values as a percent of total volume\n",
    "        df['cumulative_net_short_percent'] = df['cumulative_net_short'] / (df['totalvolume'] * df['net_short_shares']).rolling(window=days).sum() * 100\n",
    "        df['cumulative_short_exempt_percent'] = df['cumulative_short_exempt'] / (df['totalvolume'] * df['net_short_shares']).rolling(window=days).sum() * 100\n",
    "\n",
    "        if include_diff:\n",
    "            periods = [1, 5, 10, 21, 42]\n",
    "            for i in range(len(periods)):\n",
    "                for j in range(i + 1, len(periods)):\n",
    "                    df[f'cumulative_net_short_percent_{periods[i]}_div_{periods[j]}'] = df['cumulative_net_short_percent'].rolling(window=periods[i]).mean() / df['cumulative_net_short_percent'].rolling(window=periods[j]).mean()\n",
    "                    df[f'cumulative_short_exempt_percent_{periods[i]}_div_{periods[j]}'] = df['cumulative_short_exempt_percent'].rolling(window=periods[i]).mean() / df['cumulative_short_exempt_percent'].rolling(window=periods[j]).mean()\n",
    "\n",
    "        if include_roc:\n",
    "            for col in ['cumulative_net_short_percent', 'cumulative_short_exempt_percent']:\n",
    "                df[f'{col}_roc'] = df[col].pct_change() * 100\n",
    "\n",
    "        selected_cols = ['cumulative_net_short_percent', 'cumulative_short_exempt_percent']\n",
    "        if include_diff or include_roc:\n",
    "            selected_cols += [col for col in df.columns if 'cumulative_net_short_percent' in col or 'cumulative_short_exempt_percent' in col]\n",
    "\n",
    "        return df[selected_cols]\n",
    "\n",
    "# Example usage \n",
    "analysis = ShortSaleVolume()\n",
    "# df_gme_short_ratio = analysis.calculate_short_ratio_means('GME', include_roc = False)\n",
    "# df_gme_short_sale_exempt = analysis.calculate_short_exempt_means('GME', include_roc = False)\n",
    "# df_gme_investment_values = analysis.calculate_investment_values('GME', include_roc = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a0409e-13f1-4c91-8198-c4bbe738b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "class GreekAnalysis:\n",
    "    def __init__(self):\n",
    "        self.db_params = {\n",
    "            'user': 'USER_STRING_HERE',    #removed for Git\n",
    "            'password': 'PW_STRING_HERE',  #removed for Git\n",
    "            'host': 'mads-capstone.cmohac77hep9.eu-north-1.rds.amazonaws.com',\n",
    "            'port': 5432,\n",
    "            'database': 'mads'\n",
    "        }\n",
    "\n",
    "    def get_greeks_data(self, ticker, greek_type):\n",
    "        with psycopg2.connect(**self.db_params) as db_connection:\n",
    "            db_connection.autocommit = True\n",
    "            with db_connection.cursor() as cursor:\n",
    "                select_query = \"SELECT * FROM greeks3 WHERE ticker=%s AND GREEK=%s\"\n",
    "                cursor.execute(select_query, (ticker, greek_type))\n",
    "                rows = cursor.fetchall()\n",
    "                df = pd.DataFrame(rows, columns=[\"ID\", \"DATE\", \"INCREMENT\", \"VALUE\", \"TICKER\", \"GREEK\", \"OPTION_TYPE\"])\n",
    "        return df\n",
    "\n",
    "    def analyze_data(self, df, greek_type):\n",
    "        merged_df = self._prepare_merged_dataframe(df, greek_type)\n",
    "        merged_df[f'{greek_type}_Skew'] = merged_df[f'{greek_type}_Call'] / merged_df[f'{greek_type}_Put']\n",
    "        merged_df[f'{greek_type}_Time_Spread'] = merged_df[f'{greek_type}_30'] / merged_df[f'{greek_type}_90']\n",
    "        return merged_df[[f'{greek_type}_30', f'{greek_type}_Skew', f'{greek_type}_Time_Spread']]\n",
    "\n",
    "    def _prepare_merged_dataframe(self, df, greek_type):\n",
    "        inc30_all = df[(df['INCREMENT'] == 30) & (df['OPTION_TYPE'] == 'all')]\n",
    "        inc30_call = df[(df['INCREMENT'] == 30) & (df['OPTION_TYPE'] == 'call')]\n",
    "        inc30_put = df[(df['INCREMENT'] == 30) & (df['OPTION_TYPE'] == 'put')]\n",
    "        inc90_all = df[(df['INCREMENT'] == 90) & (df['OPTION_TYPE'] == 'all')]\n",
    "\n",
    "        merged_df = pd.DataFrame(index=inc30_all['DATE'].unique())\n",
    "        merged_df[f'{greek_type}_30'] = inc30_all.groupby('DATE')['VALUE'].mean()\n",
    "        merged_df[f'{greek_type}_Call'] = inc30_call.groupby('DATE')['VALUE'].mean()\n",
    "        merged_df[f'{greek_type}_Put'] = inc30_put.groupby('DATE')['VALUE'].mean()\n",
    "        merged_df[f'{greek_type}_90'] = inc90_all.groupby('DATE')['VALUE'].mean()\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    def _add_rolling_features(self, df, greek_type):\n",
    "        periods = [1, 5, 10, 21, 42]\n",
    "        for col in [f'{greek_type}_30', f'{greek_type}_Skew', f'{greek_type}_Time_Spread']:\n",
    "            for period in periods:\n",
    "                df[f'{col}_rolling_{period}'] = df[col].rolling(window=period).mean()\n",
    "        return df\n",
    "\n",
    "    def _add_z_score_features(self, df, greek_type):\n",
    "        rolling_window = 90\n",
    "        for col in [f'{greek_type}_30', f'{greek_type}_Skew', f'{greek_type}_Time_Spread']:\n",
    "            df[f'{col}_z_score'] = (df[col] - df[col].rolling(window=rolling_window).mean()) / df[col].rolling(window=rolling_window).std()\n",
    "        return df\n",
    "\n",
    "    def get_analysis_for_ticker(self, ticker, greek_type='iv', include_rolling=False, include_z_score=False):\n",
    "        df = self.get_greeks_data(ticker, greek_type)\n",
    "        analysis_df = self.analyze_data(df, greek_type)\n",
    "        if include_rolling:\n",
    "            analysis_df = self._add_rolling_features(analysis_df, greek_type)\n",
    "        if include_z_score:\n",
    "            analysis_df = self._add_z_score_features(analysis_df, greek_type)\n",
    "        return analysis_df.sort_index()\n",
    "\n",
    "# Example usage:\n",
    "greek_analysis = GreekAnalysis()\n",
    "# df_gme_iv = greek_analysis.get_analysis_for_ticker('GME', 'iv', include_rolling = True, include_z_score = True)\n",
    "# df_gme_gamma = greek_analysis.get_analysis_for_ticker('GME', 'gamma', include_rolling = True, include_z_score = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28ad1f3-3991-40de-bf1a-6b608d6d9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolatilityAnalysis(GreekAnalysis):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sdate = '20160101'\n",
    "        self.edate = '20231110'\n",
    "        \n",
    "    # Function to calculate HV for a given OHLCV DataFrame\n",
    "    def calculate_hv(self, ohlcv_df, look_forward=30):\n",
    "        # Calculate daily returns\n",
    "        daily_returns = ohlcv_df['close'].pct_change()\n",
    "\n",
    "        # Compute rolling standard deviation of daily returns\n",
    "        rolling_std = daily_returns.rolling(window = look_forward).std()\n",
    "\n",
    "        # HV is the annualized standard deviation\n",
    "        hv = rolling_std * np.sqrt(252)\n",
    "\n",
    "        return hv\n",
    "\n",
    "    def compare_iv_hv(self, ticker, shift_hv = False):\n",
    "        \n",
    "        # Get ticker data\n",
    "        ohlcv_df = finance.get_data(ticker, self.sdate, self.edate)\n",
    "        \n",
    "        # Pull IV30 data\n",
    "        iv30_df = self.get_greeks_data(ticker, 'iv')\n",
    "        iv30_df = iv30_df[(iv30_df['GREEK'] == 'iv') & (iv30_df['OPTION_TYPE'] == 'all') & (iv30_df['INCREMENT'] == 30)].copy()\n",
    "        iv30_df['date'] = pd.to_datetime(iv30_df['DATE'])\n",
    "        iv30_df.rename({'VALUE':'iv30'}, inplace = True, axis = 1)\n",
    "\n",
    "        # Calculate HV\n",
    "        hv_df = self.calculate_hv(ohlcv_df)\n",
    "\n",
    "        # Align and compare IV30 and HV\n",
    "        # Ensure iv30_df and hv_df have the same date index\n",
    "        comparison_df = pd.DataFrame()\n",
    "        comparison_df['IV30'] = iv30_df.set_index('date').sort_index()['iv30']\n",
    "        \n",
    "        # Are we shifting HV? \n",
    "        if shift_hv:\n",
    "            comparison_df['HV'] = hv_df.shift(-30)  # Adjust as necessary\n",
    "        else:\n",
    "            comparison_df['HV'] = hv_df\n",
    "        \n",
    "        # Add to dataframe and return \n",
    "        comparison_df['IV_HV_Difference'] = comparison_df['IV30'] - comparison_df['HV']\n",
    "\n",
    "        return comparison_df['IV_HV_Difference']\n",
    "    \n",
    "    def calculate_vwap(self, ohlcv_df, rolling_window = 90):  \n",
    "        ohlcv_df['Typical_Price'] = (ohlcv_df['high'] + ohlcv_df['low'] + ohlcv_df['close']) / 3\n",
    "        ohlcv_df['TP_Volume'] = ohlcv_df['Typical_Price'] * ohlcv_df['volume']\n",
    "\n",
    "        # Calculate rolling TP_Volume and rolling volume\n",
    "        ohlcv_df['Rolling_TP_Volume'] = ohlcv_df['TP_Volume'].rolling(window=rolling_window).sum()\n",
    "        ohlcv_df['Rolling_Volume'] = ohlcv_df['volume'].rolling(window=rolling_window).sum()\n",
    "\n",
    "        # Compute rolling VWAP\n",
    "        ohlcv_df['VWAP'] = ohlcv_df['Rolling_TP_Volume'] / ohlcv_df['Rolling_Volume']\n",
    "\n",
    "        # Calculate the percentage difference between close and VWAP\n",
    "        ohlcv_df['vwap_close_pct'] = ohlcv_df['close'] / ohlcv_df['VWAP']\n",
    "\n",
    "        return ohlcv_df\n",
    "\n",
    "    def compare_price_to_vwap(self, ticker = None, ohlcv_df = None):\n",
    "        \n",
    "        # Optionally, grab data\n",
    "        if not isinstance(ohlcv_df, pd.DataFrame):\n",
    "            ohlcv_df = finance.get_data(ticker, self.sdate, self.edate)\n",
    "            \n",
    "        ohlcv_df = self.calculate_vwap(ohlcv_df)\n",
    "        return ohlcv_df['vwap_close_pct']\n",
    "    \n",
    "# Example usage\n",
    "price_iv_analysis = VolatilityAnalysis()\n",
    "# df_iv_hv = price_iv_analysis.compare_iv_hv('GME')\n",
    "# df_vwap = price_iv_analysis.compare_price_to_vwap('GME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948aa21e-4618-4199-98f9-cecefaae5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def return_etf_holdings(ticker = 'SPY'):\n",
    "\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "    res = requests.get(\"https://www.zacks.com/funds/etf/%s/holding\"%ticker,  headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    js = None\n",
    "    for script in soup.find_all(\"script\"):\n",
    "        if \"etf_holdings.formatted_data = \" in str(script):\n",
    "    #    if \"etf_holdings\" in str(script):\n",
    "            js = str(script)\n",
    "    holdings = []\n",
    "    # for line in js.text.split(\"[\"):\n",
    "    for line in js.split(\"[\"):\n",
    "        if \"rel=\" in line:\n",
    "            line_soup = BeautifulSoup(line, 'html.parser')\n",
    "            #holding = line_soup.find(\"a\")[\"alt\"].strip('\\\\\"')\n",
    "            holding = line_soup.find('a')['rel'][0].strip('\\\\\"')\n",
    "            holdings.append(holding)\n",
    "\n",
    "    return holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815ab7ee-eb9c-403d-a37c-3a29fd843d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = return_etf_holdings('IWV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1f928a-df97-48ea-a714-807168d81908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc2d786-a25b-44fa-b1d4-c68a5168b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1db9f0f-193e-475f-8d08-cc4e547df825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2018-08-01'\n",
    "end_date = '2023-11-15'\n",
    "\n",
    "# Create a calendar for NYSE\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "# Get the open market days within the date range\n",
    "market_days = nyse_calendar.valid_days(start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Convert to a list of dates in string format (if needed)\n",
    "market_days_str = market_days.strftime('%Y-%m-%d').tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc8927-c541-4889-859a-ffcc519ed747",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create enormous dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67804ad-ec31-4cdd-88bd-30ef7b466520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL <class 'requests.exceptions.ConnectionError'> ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9821/323460992.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  current_z_score = (df.iloc[i]['PriceChange'] - rolling_mean[i]) / rolling_std[i]\n",
      "/tmp/ipykernel_9821/323460992.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  future_z_score = (future_price_change - rolling_mean[i+lag_day]) / rolling_std[i+lag_day]\n",
      "/opt/conda/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sdate = '20180816'\n",
    "edate = '20231115'\n",
    "\n",
    "df_repo = []\n",
    "for ticker in tqdm(tickers):\n",
    "    \n",
    "    try:\n",
    "        # Get data\n",
    "        df_data = get_data(ticker, sdate, edate)\n",
    "\n",
    "        # Calc positive and negative classes\n",
    "        price_jumps_df = identify_price_jumps(df_data, z_score_threshold=2.5, stability_threshold=1, include_negative_class=True, remove_duplicate_price_jump_dates = False)\n",
    "\n",
    "        # Get other data\n",
    "        df_short_ratio = analysis.calculate_short_ratio_means(ticker, include_diff=True, include_roc=True)\n",
    "        df_short_sale_exempt = analysis.calculate_short_exempt_means(ticker, include_diff=True, include_roc=True)\n",
    "        df_investment_values = analysis.calculate_investment_values(ticker, include_diff=True, include_roc=True)\n",
    "\n",
    "        df_iv = greek_analysis.get_analysis_for_ticker(ticker, 'iv', include_rolling = True, include_z_score = True)\n",
    "        df_gamma = greek_analysis.get_analysis_for_ticker(ticker, 'gamma', include_rolling = True, include_z_score = True)\n",
    "\n",
    "        df_iv_hv = price_iv_analysis.compare_iv_hv(ticker)\n",
    "        df_vwap = price_iv_analysis.compare_price_to_vwap(ticker)\n",
    "\n",
    "        # Merge datasets together\n",
    "        additional_dfs = [df_short_ratio, df_short_sale_exempt, df_investment_values, df_iv, df_gamma, df_iv_hv, df_vwap]\n",
    "        for df_ in additional_dfs:\n",
    "            df_.index = pd.to_datetime(df_.index)\n",
    "        merged_df = merge_additional_data(price_jumps_df, additional_dfs)\n",
    "\n",
    "        # Save to repo and continue\n",
    "        df_repo.append(merged_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(ticker, type(e), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a1e06-5f85-43f9-a0ad-5ec7e67bab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
